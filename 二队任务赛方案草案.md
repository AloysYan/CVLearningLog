### 任务赛完整视觉方案

| 比赛阶段 | 步骤名称 | 硬件动作 (IMX577 + TOF) | 软件/算法技术栈 | 视觉组核心策略 & 逻辑 (针对单点TOF优化) |
| --- | --- | --- | --- | --- |
| **0. 启动准备** | **高分策略获取** | 云台抬起，**IMX577** 对准场地后方的高处显示屏。 | **PaddleOCR** (或 Tesseract) | 1. 裁剪画面只保留题目区域。<br>2. 识别算式 (如 `12+5`)。<br>3. 计算 `17 % 4 = 1`。<br>4. 发布话题 `/target_bonus_zone` (比如告诉决策层：灰色/工具区是双倍分)。
| **1. 全局搜索** | **寻找最近物资箱** | **IMX577** (广角优势) 扫描前方区域。 | **YOLOv8n** (TensorRT加速？) | 1. 识别视野内所有箱子 (`food`, `tool`, etc.)。<br>2. 选择 bounding box 面积最大（离得最近）或位于画面最中心的那个作为当前目标。<br>3. 输出目标在画面中的像素偏差 `(dx, dy)`。
| **2. 接近目标** | **闭环视觉引导 (粗调)** | 机器人底盘移动，保持相机盯着箱子。 | **PID 控制算法** | **策略：** 只要箱子不在画面中心，就给电控发旋转指令。<br>**逻辑**：`cmd_vel.angular.z = P * (center_x - box_x)`。<br>**目的**：利用大广角防止跟丢，确保存放区的箱子始终在视野内。 |  |
| **3. 精准定位** | **TOF 测距对齐 (精调)** | 机器人停止移动，微调角度，使 **TOF 光斑** 绝对打在箱子上。 | **数据融合** (Kalman Filter 简单版) | **关键解决：**<br>因为 TOF 只能测一点，必须保证 **YOLO框的中心点 ≈ 画面中心点**。<br>当 `abs(dx) < 阈值` 时，读取 TOF 距离数据，发送给机械臂：“前方 35.5cm 处有箱子，准备抓取”。 |  |
| **4. 抓取物资** | **盲抓或微修正** | 机械臂伸出，**IMX577** 可能会因为距离太近而看只到箱子局部。 | **OpenCV** (Canny边缘检测/颜色分割) | 如果此时摄像头还能看到，利用 OpenCV 提取箱子边缘直线，修正机械臂末端的偏航角 (Yaw)，保证抓手和箱子面平行，防止抓歪。
| **5. 搬运归位** | **寻找归位区** | 机器人携带箱子，**IMX577** 寻找对应的地面色块。 | **YOLOv8** 或 **OpenCV HSV** | 1. 根据手里抓的箱子类型 (如食品-绿色)，检索对应的归位区 (绿色方块)。<br>2. 识别地面上的绿色矩形区域。<br>3. 计算矩形中心与机器人的相对角度。
| **6. 放置物资** | **防压线放置** | 接近归位区，利用 **TOF** 测量与墙壁或地面的距离。 | **几何计算** | **策略：** 规则严格要求不能压线 (100扣成60分)。<br>1. 视觉识别归位区的**四条边框**。<br>2. 引导机器人走到正中间。<br>3. TOF 辅助判断是否已经完全进入区域 (例如离墙距离 < 60cm)。

